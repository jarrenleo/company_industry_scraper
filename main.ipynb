{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import csv\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["company_names = []\n","primary_ssic_description = []\n","primary_user_described_activity = []\n","\n","def read_csv(csv_file):\n","    # Read company names from csv file and store them into company_names[]\n","    with open(csv_file, \"r\", encoding = \"ISO-8859-1\") as file:\n","        csv_reader = csv.DictReader(file)\n","        for row in csv_reader:\n","            company_names.append(row[\"Name\"])"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def find_url_path(soup, text):\n","    # Try to find the company name that matches the one in the csv file\n","    element = soup.find(\"a\", text = text)\n","    if element:\n","        return element.get(\"href\")\n","    else:\n","        # Else get the first company from the search results\n","        first_element = soup.find_all(\"a\")[13]\n","        return first_element.get(\"href\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def get_url_path(company_name):\n","    # Convert company name to search parameter\n","    search_parameter = company_name.replace(\" \", \"+\")\n","    response = requests.get(f\"https://www.companies.sg/?NodeSearch%5Buen%5D=&NodeSearch%5Bentity_name%5D={search_parameter}\")\n","    soup = BeautifulSoup(response.text, \"lxml\")\n","    \n","    return find_url_path(soup, company_name)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def find_description(soup, text, description_list):\n","    # Try to find the description header that matches the one we need \n","    element = soup.find(\"span\", text = text)\n","    if element:\n","        description_list.append(element.find_next_sibling(\"label\").get_text())\n","    else:\n","        # Else, set as no description\n","        description_list.append(\"\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def get_industry_description(url_path):\n","    try:\n","        # If invalid url path, set as no description\n","        if not url_path.startswith(\"/\"):\n","            primary_ssic_description.append(\"\")\n","            primary_user_described_activity.append(\"\")\n","            return\n","\n","        response = requests.get(f\"https://www.companies.sg{url_path}\")\n","        soup = BeautifulSoup(response.text, \"lxml\")\n","\n","        find_description(soup, \"Primary Ssic Description\", primary_ssic_description)\n","        find_description(soup, \"Primary User Described Activity\", primary_user_described_activity)\n","    except Exception as e:\n","        print(f\"An error occcured: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def write_data_to_csv(csv_file):\n","    df = pd.read_csv(csv_file, encoding = \"ISO-8859-1\")\n","    df[\"Primary SSIC Description\"] = primary_ssic_description\n","    df[\"Primary User Described Activity\"] = primary_user_described_activity\n","    df.to_csv(csv_file, index = False)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def get_data(csv_file):\n","    read_csv(csv_file)\n","\n","    for company_name in company_names:\n","        print(company_name)\n","        url_path = get_url_path(company_name)\n","        get_industry_description(url_path)\n","    \n","    write_data_to_csv(csv_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["get_data(\"./Company_1.csv\")"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
